{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from experiment.utils import dbutils, logger, transformation\n",
    "from experiment.utils.tables.upload_tasks_table import UploadTasksTable\n",
    "from experiment.api import label_studio\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = dbutils.DatabaseUtils()\n",
    "lg = logger.Logger(\n",
    "    logging_level=\"DEBUG\",\n",
    "    output_path=transformation.get_project_root() / \"tmp\" / \"report_prompting.log\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_N_MORE_REPORTS = 200\n",
    "PROMPT = \"Perform the following transformation on the report: Translate into English\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_raw, Base = UploadTasksTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m11:52:22  Running with dbt=1.6.1\n",
      "\u001b[0m11:52:22  Registered adapter: postgres=1.6.1\n",
      "\u001b[0m11:52:22  [\u001b[33mWARNING\u001b[0m]: Did not find matching node for patch with name 'annotations' in the 'models' section of file 'models/schema.yml'\n",
      "\u001b[0m11:52:22  Found 8 models, 5 sources, 0 exposures, 0 metrics, 689 macros, 0 groups, 0 semantic models\n",
      "\u001b[0m11:52:22  \n",
      "\u001b[0m11:52:24  Concurrency: 5 threads (target='prod')\n",
      "\u001b[0m11:52:24  \n",
      "\u001b[0m11:52:24  1 of 1 START sql incremental model annotation.upload_tasks ..................... [RUN]\n",
      "\u001b[0m11:52:26  1 of 1 OK created sql incremental model annotation.upload_tasks ................ [\u001b[32mMERGE 25687\u001b[0m in 2.07s]\n",
      "\u001b[0m11:52:27  \n",
      "\u001b[0m11:52:27  Finished running 1 incremental model in 0 hours 0 minutes and 4.44 seconds (4.44s).\n",
      "\u001b[0m11:52:27  \n",
      "\u001b[0m11:52:27  \u001b[32mCompleted successfully\u001b[0m\n",
      "\u001b[0m11:52:27  \n",
      "\u001b[0m11:52:27  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n"
     ]
    }
   ],
   "source": [
    "# # run the dbt model to generate tables from scratch\n",
    "# Base.metadata.create_all(db.engine)\n",
    "# db.run_dbt_model('upload_tasks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Select Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_id</th>\n",
       "      <th>patient_no</th>\n",
       "      <th>protocol_no</th>\n",
       "      <th>report_original</th>\n",
       "      <th>report_length</th>\n",
       "      <th>report_prompted</th>\n",
       "      <th>patient_report_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5408</td>\n",
       "      <td>2005183286</td>\n",
       "      <td>21302877</td>\n",
       "      <td>RAPOR TARİHİ: 24.06.2021     FİLM NO: 12217711...</td>\n",
       "      <td>79</td>\n",
       "      <td></td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6125</td>\n",
       "      <td>2006000036</td>\n",
       "      <td>22202602</td>\n",
       "      <td>RAPOR TARİHİ:01/02/2022            TETKİK NO: ...</td>\n",
       "      <td>83</td>\n",
       "      <td></td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16913</td>\n",
       "      <td>2008509284</td>\n",
       "      <td>22344550</td>\n",
       "      <td>RAPOR TARİHİ: 21/02/2022   FİLM NO:12506694\\n\\...</td>\n",
       "      <td>165</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16909</td>\n",
       "      <td>2008509284</td>\n",
       "      <td>22344550</td>\n",
       "      <td>RAPOR TARİHİ:08/02/2022   FİLM NO:12506525\\n\\n...</td>\n",
       "      <td>113</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>2004004697</td>\n",
       "      <td>22023602</td>\n",
       "      <td>RAPOR TARİHİ:27/12/2021   FİLM NO:\\n\\nKontrast...</td>\n",
       "      <td>128</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   report_id  patient_no  protocol_no  \\\n",
       "0       5408  2005183286     21302877   \n",
       "1       6125  2006000036     22202602   \n",
       "2      16913  2008509284     22344550   \n",
       "3      16909  2008509284     22344550   \n",
       "4         26  2004004697     22023602   \n",
       "\n",
       "                                     report_original  report_length  \\\n",
       "0  RAPOR TARİHİ: 24.06.2021     FİLM NO: 12217711...             79   \n",
       "1  RAPOR TARİHİ:01/02/2022            TETKİK NO: ...             83   \n",
       "2  RAPOR TARİHİ: 21/02/2022   FİLM NO:12506694\\n\\...            165   \n",
       "3  RAPOR TARİHİ:08/02/2022   FİLM NO:12506525\\n\\n...            113   \n",
       "4  RAPOR TARİHİ:27/12/2021   FİLM NO:\\n\\nKontrast...            128   \n",
       "\n",
       "  report_prompted  patient_report_count  \n",
       "0                                    27  \n",
       "1                                    26  \n",
       "2                                    20  \n",
       "3                                    20  \n",
       "4                                    19  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get reports directly from database\n",
    "query = \"\"\"\n",
    "            SELECT * FROM annotation.upload_tasks ut \n",
    "            ORDER BY patient_report_count DESC, report_length DESC \n",
    "        \"\"\"\n",
    "\n",
    "# get values from the database\n",
    "df_reports = db.read_sql_query(query)\n",
    "df_reports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get annotated reports \n",
    "query = \"\"\"\n",
    "            SELECT \n",
    "                DISTINCT data ->> 'patient_no' as patient_no\n",
    "            FROM task\n",
    "            WHERE is_labeled = TRUE\n",
    "        \"\"\"\n",
    "\n",
    "# get values from the database\n",
    "annotated_patient_nos = db.read_sql_query(query)[\"patient_no\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tasks that have been prompted\n",
    "query = \"\"\"\n",
    "            SELECT \n",
    "                report_id\n",
    "            FROM annotation.upload_tasks\n",
    "            WHERE report_prompted != '' \n",
    "        \"\"\"\n",
    "\n",
    "# get values from the database\n",
    "upload_tasks_prompted = db.read_sql_query(query)[\"report_id\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only non-prompted reports & non-annotated patients\n",
    "df_upload_tasks = (\n",
    "    df_reports.loc[~df_reports[\"patient_no\"].isin(annotated_patient_nos)]\n",
    "    .loc[~df_reports[\"report_id\"].isin(upload_tasks_prompted)]\n",
    "    .head(PROMPT_N_MORE_REPORTS)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Prompt Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for default-gpt-3.5-turbo in organization org-G5GXNK7ybi1FeYo1ZA7weCK9 on requests per day. Limit: 200 / day. Please try again in 7m12s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data_to_insert \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m _, row \u001b[39min\u001b[39;00m df_upload_tasks\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     data_to_insert\u001b[39m.\u001b[39mappend(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mreport_id\u001b[39m\u001b[39m\"\u001b[39m: row[\u001b[39m\"\u001b[39m\u001b[39mreport_id\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mpatient_no\u001b[39m\u001b[39m\"\u001b[39m: row[\u001b[39m\"\u001b[39m\u001b[39mpatient_no\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mprotocol_no\u001b[39m\u001b[39m\"\u001b[39m: row[\u001b[39m\"\u001b[39m\u001b[39mprotocol_no\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mreport_original\u001b[39m\u001b[39m\"\u001b[39m: row[\u001b[39m\"\u001b[39m\u001b[39mreport_original\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mreport_prompted\u001b[39m\u001b[39m\"\u001b[39m: transformation\u001b[39m.\u001b[39;49mprompt_report(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                 row[\u001b[39m\"\u001b[39;49m\u001b[39mreport_original\u001b[39;49m\u001b[39m\"\u001b[39;49m], prompt\u001b[39m=\u001b[39;49mPROMPT\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             ),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mreport_length\u001b[39m\u001b[39m\"\u001b[39m: row[\u001b[39m\"\u001b[39m\u001b[39mreport_length\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mpatient_report_count\u001b[39m\u001b[39m\"\u001b[39m: row[\u001b[39m\"\u001b[39m\u001b[39mpatient_report_count\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     db\u001b[39m.\u001b[39mupsert_values(reports_raw, data_to_insert, cols_to_upsert, [\u001b[39m\"\u001b[39m\u001b[39mreport_id\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokasci/Desktop/reports/notebooks/de_1_2_prepare_ls_tasks.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# openai restriction: 3 RPM - 200 RPD\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/reports/src/experiment/utils/transformation.py:105\u001b[0m, in \u001b[0;36mprompt_report\u001b[0;34m(report, prompt)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''The `prompt_report` function takes a report in a specified language and uses OpenAI's\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mGPT-3.5-turbo model to translate it into English.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    103\u001b[0m openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mOPEN_AI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    106\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    107\u001b[0m     messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m    108\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mprompt\u001b[39m}\u001b[39;49;00m\u001b[39m: \u001b[39;49m\u001b[39m{\u001b[39;49;00mreport\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m}\n\u001b[1;32m    109\u001b[0m     ],\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    112\u001b[0m prompted_report \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m prompted_report \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/reports/.venv/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Desktop/reports/.venv/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Desktop/reports/.venv/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Desktop/reports/.venv/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/reports/.venv/lib/python3.11/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    764\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for default-gpt-3.5-turbo in organization org-G5GXNK7ybi1FeYo1ZA7weCK9 on requests per day. Limit: 200 / day. Please try again in 7m12s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method."
     ]
    }
   ],
   "source": [
    "cols_to_upsert = df_upload_tasks.columns.to_list()\n",
    "cols_to_upsert.remove(\"report_id\")\n",
    "data_to_insert = []\n",
    "for _, row in df_upload_tasks.iterrows():\n",
    "    try:\n",
    "        data_to_insert.append(\n",
    "            {\n",
    "                \"report_id\": row[\"report_id\"],\n",
    "                \"patient_no\": row[\"patient_no\"],\n",
    "                \"protocol_no\": row[\"protocol_no\"],\n",
    "                \"report_original\": row[\"report_original\"],\n",
    "                \"report_prompted\": transformation.prompt_report(\n",
    "                    report=row[\"report_original\"], prompt=PROMPT\n",
    "                ),\n",
    "                \"report_length\": row[\"report_length\"],\n",
    "                \"patient_report_count\": row[\"patient_report_count\"],\n",
    "            }\n",
    "        )\n",
    "    \n",
    "\n",
    "        db.upsert_values(reports_raw, data_to_insert, cols_to_upsert, [\"report_id\"])\n",
    "\n",
    "        time.sleep(20)\n",
    "    except openai.error.RateLimitError:\n",
    "        # openai restriction: 3 RPM - 200 RPD\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Upload Tasks to Label Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get reports directly from database\n",
    "query = \"\"\"\n",
    "            SELECT\n",
    "                report_id,\n",
    "                patient_no,\n",
    "                protocol_no,\n",
    "                report_original,\n",
    "                report_prompted as text,\n",
    "                report_length,\n",
    "                patient_report_count\n",
    "            FROM\n",
    "                annotation.upload_tasks\n",
    "            WHERE\n",
    "                report_id NOT IN (\n",
    "                SELECT\n",
    "                    (DATA ->> 'report_id')::INT AS report_id\n",
    "                FROM\n",
    "                    public.task)\n",
    "                AND report_prompted != ''\n",
    "        \"\"\"\n",
    "\n",
    "# get values from the database\n",
    "df_upload_tasks = db.read_sql_query(query)\n",
    "\n",
    "# output tasks as a csv file\n",
    "output_path = (\n",
    "    transformation.get_project_root() / \"tmp\" / \"data\" / \"upload_tasks.csv\"\n",
    ")\n",
    "df_upload_tasks.to_csv(output_path, index=False)\n",
    "df_upload_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload tasks to label studio\n",
    "label_studio.upload_csv_tasks(csv_path=output_path, project_id=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_studio.stop_label_studio()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "# from datasets import load_dataset\n",
    "\n",
    "import dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token =os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "huggingface_hub.login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "#https://huggingface.co/spaces/sambanovasystems/BLOOMChat\n",
    "\n",
    "model_name = \"sambanovasystems/BLOOMChat-176B-v1\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the text to translate\n",
    "text_to_translate = \"\"\"Kafa tabanı ve verteks arasından elde olunan kesitlerde Kafa kaidesi ve kalvarial kemik yapılar normal sınırlardadır 4. ventrikül normalden geniş simetrik orta hattadır. CPA ve prepontin sisternler geniş izlenmektedir. Serebellar folyalar belirgindir. 3. ventrikül ve lateral ventriküller geniş olarak izlenmektedir. 3. ventrikül orta hatta lokalizedir. Beyin orta hat yapılarında yer değiştirme saptanmamıştır Serebral sulkus ve sisternalar genişlemiştir. İntrakranial hipo veya hiperdens sınırlanabilen patoloji saptanmadı Sol frontal bölge ve orbita lateral kesimi komşuluğunda cilt altı yağlı dokuda hematoma bağlı kalınlaşma izlenmektedir.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    input_ids = tokenizer.encode(text_to_translate, return_tensors=\"pt\")\n",
    "    chat_output = model.generate(input_ids, max_length=50, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "\n",
    "    bot_response = tokenizer.decode(chat_output[0], skip_special_tokens=True)\n",
    "    print(\"Bot:\", bot_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment.api import mlflow as mlflow_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with ID 1bd4227822cc4d4b850e5925d77ebf46 has been permanently deleted.\n",
      "Run with ID 0895a4f969da4b57b498098ec18b52fb has been permanently deleted.\n",
      "Run with ID c4ca80c995034e21ba9e9495866f4320 has been permanently deleted.\n",
      "Run with ID 980c5ac9141942c19dd7cc65546914c8 has been permanently deleted.\n",
      "Run with ID 6907e2c96c2a414f8770330bb20b07f1 has been permanently deleted.\n",
      "Run with ID 3dc53e4c52024401ade481d294d2ef42 has been permanently deleted.\n"
     ]
    }
   ],
   "source": [
    "mlflow = mlflow_api.MLFlow()\n",
    "\n",
    "# clean with garbage collection\n",
    "mlflow.clean(gc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the tracking server\n",
    "mlflow.run_tracking_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-30 13:55:30 +0300] [98180] [INFO] Starting gunicorn 21.2.0\n",
      "[2023-08-30 13:55:30 +0300] [98180] [INFO] Listening at: http://0.0.0.0:9999 (98180)\n",
      "[2023-08-30 13:55:30 +0300] [98180] [INFO] Using worker: sync\n",
      "[2023-08-30 13:55:30 +0300] [98181] [INFO] Booting worker with pid: 98181\n",
      "[2023-08-30 13:55:30 +0300] [98182] [INFO] Booting worker with pid: 98182\n",
      "[2023-08-30 13:55:30 +0300] [98183] [INFO] Booting worker with pid: 98183\n",
      "[2023-08-30 13:55:30 +0300] [98184] [INFO] Booting worker with pid: 98184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "2023/08/30 13:55:41 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n",
      "Downloading artifacts: 100%|██████████| 6/6 [00:00<00:00,  6.06it/s]\n",
      "2023/08/30 13:55:43 INFO mlflow.pyfunc.backend: === Running command 'exec gunicorn --timeout=60 -b 127.0.0.1:1234 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "[2023-08-30 13:55:43 +0300] [98188] [INFO] Starting gunicorn 21.2.0\n",
      "[2023-08-30 13:55:43 +0300] [98188] [INFO] Listening at: http://127.0.0.1:1234 (98188)\n",
      "[2023-08-30 13:55:43 +0300] [98188] [INFO] Using worker: sync\n",
      "[2023-08-30 13:55:43 +0300] [98189] [INFO] Booting worker with pid: 98189\n"
     ]
    }
   ],
   "source": [
    "# get the best run \n",
    "best_run = mlflow.get_best_run_by_metric(\"NLP Experiments\", \"accuracy\")\n",
    "best_run_id = best_run[\"run_id\"]\n",
    "\n",
    "# serve the best model\n",
    "mlflow.run_inference_server(best_run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

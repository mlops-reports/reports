{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "# import pathlib\n",
    "\n",
    "from experiment.api import label_studio\n",
    "from experiment.utils import transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variables\n",
    "ANNOTATIONS_PATH = transformation.get_project_root() / \"data\" / \"output\" / \"annotations.json\"\n",
    "DB_PATH = transformation.get_project_root() / \"data\" / \"output\" / \"db.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scaling dynos... done, now running \u001b[32mweb\u001b[39m at 1:Basic\n"
     ]
    }
   ],
   "source": [
    "# start the heroku server if stopped\n",
    "label_studio.start_label_studio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  141k  100  141k    0     0  77317      0  0:00:01  0:00:01 --:--:-- 77524\n"
     ]
    }
   ],
   "source": [
    "# get the annotations from the label studio server\n",
    "label_studio.download_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON data from file\n",
    "with open(ANNOTATIONS_PATH, \"r\") as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store flattened data\n",
    "flattened_data_list = []\n",
    "\n",
    "# Flatten the nested data for each entry in the JSON data\n",
    "for entry in json_data:\n",
    "    annotations = entry.get(\"annotations\", [])\n",
    "    data = entry.get(\"data\", [])\n",
    "    for annotation in annotations:\n",
    "        result = annotation.get(\"result\", [])\n",
    "        for res in result:\n",
    "            value = res.get(\"value\", {})\n",
    "            flattened_data = {\n",
    "                # \"id\": entry[\"id\"],\n",
    "                \"annotation_id\": annotation[\"id\"],\n",
    "                # \"completed_by\": annotation[\"completed_by\"],\n",
    "                \"type\": res[\"type\"],\n",
    "                # \"end\": value.get(\"end\", None),\n",
    "                # \"start\": value.get(\"start\", None),\n",
    "                \"text\": value.get(\"text\", None),\n",
    "                \"labels\": value.get(\"labels\", None),\n",
    "                \"choices\": value.get(\"choices\", None),\n",
    "                # \"origin\": res.get(\"origin\", None),\n",
    "                # \"to_name\": res.get(\"to_name\", None),\n",
    "                # \"from_name\": res.get(\"from_name\", None),\n",
    "                \"full_text\": data.get(\"text\", None),\n",
    "                \"study_no\": data.get(\"study_no\", None),\n",
    "                \"patient_no\": data.get(\"patient_no\", None),\n",
    "                \"report_date\": data.get(\"report_date\", None),\n",
    "                \"report_count\": data.get(\"report_count\", None),\n",
    "            }\n",
    "            flattened_data_list.append(flattened_data)\n",
    "\n",
    "# Convert to a Pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data_list)\n",
    "\n",
    "with open(DB_PATH, \"w\") as outfile:\n",
    "    json_data = {\"annotated\": list(set(df[\"patient_no\"].to_list()))}\n",
    "    json.dump(json_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate labels and choices\n",
    "df_labels = df.loc[df.type == \"labels\"]\n",
    "df_choices = df.loc[df.type == \"choices\"]\n",
    "\n",
    "# merge labels & choices & select only the relevant columns\n",
    "df_labels_choices = (\n",
    "    df_labels.groupby(\"annotation_id\")\n",
    "    .agg({\"text\": \" \".join})\n",
    "    .reset_index()\n",
    "    .merge(df_choices, on=\"annotation_id\", how=\"left\")\n",
    ")[\n",
    "    [\n",
    "        \"annotation_id\",\n",
    "        # \"study_no\",\n",
    "        \"patient_no\",\n",
    "        \"report_date\",\n",
    "        # \"report_count\",\n",
    "        \"full_text\",\n",
    "        \"text_x\",\n",
    "        \"choices\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\"text_x\": \"relevant_text\", \"choices\": \"classifications\"}\n",
    ")\n",
    "\n",
    "# update the classifications column type\n",
    "df_labels_choices[\"classifications\"] = df_labels_choices[\"classifications\"].astype(str)\n",
    "\n",
    "# filter excluded ones\n",
    "df_final = df_labels_choices.loc[\n",
    "    ~df_labels_choices[\"classifications\"].str.contains(\"Exclude\", na=False)\n",
    "]\n",
    "\n",
    "# Define a mapping of string values to integer values\n",
    "string_to_integer_mapping = {\n",
    "    \"['Emergency']\": 0,\n",
    "    \"['Normal']\": 1,\n",
    "    \"['Non Emergency [Doctor]']\": 2,\n",
    "    \"['Non Emergency [No Doctor]']\": 3,\n",
    "}\n",
    "\n",
    "# Replace string values with integer values\n",
    "df_final[\"classifications\"] = df_final[\"classifications\"].replace(\n",
    "    string_to_integer_mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CPA ve prepontin sisternler geniş izlenmektedir. Serebellar folyalar belirgindir. 3. ventrikül ve lateral ventriküller geniş olarak izlenmektedir. Serebral sulkus ve sisternalar genişlemiştir. Periventriküler alanlarda lökoriazis ile uyumlu görünüm mevcuttur.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[\"relevant_text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>patient_no</th>\n",
       "      <th>report_date</th>\n",
       "      <th>full_text</th>\n",
       "      <th>relevant_text</th>\n",
       "      <th>classifications</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36</td>\n",
       "      <td>2004355719</td>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>Kontrastsız Beyin BT  Kafa kaidesi ve kalvaria...</td>\n",
       "      <td>Kontrastsız Beyin BT Kafa kaidesi ve kalvarial...</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2008696775</td>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>KONTRASTSIZ BEYİN BT   İnfratentorial kesitler...</td>\n",
       "      <td>Sol serebellar hemisferde sekel ??? ensefaloma...</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28</td>\n",
       "      <td>2006088545</td>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>Kontrastsız Beyin  BT tetkiki   Kafa kaidesi v...</td>\n",
       "      <td>Periventriküler derin beyaz cevherde kronik i...</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>74</td>\n",
       "      <td>2009366291</td>\n",
       "      <td>2021-06-23</td>\n",
       "      <td>Beyin BT ve orbita BT tetkiklerinde   Posterio...</td>\n",
       "      <td>Sağda orbita tavanınd frontal sinüs tabanında ...</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>61</td>\n",
       "      <td>2009021658</td>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>Beyin  BT tetkiki   Kafa kaidesi normal sınırl...</td>\n",
       "      <td>Sağ orbita üst duvarında fraktüre ait görünüm ...</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    annotation_id  patient_no report_date  \\\n",
       "18             36  2004355719  2021-06-11   \n",
       "4              19  2008696775  2020-10-13   \n",
       "12             28  2006088545  2021-06-07   \n",
       "47             74  2009366291  2021-06-23   \n",
       "37             61  2009021658  2021-06-22   \n",
       "\n",
       "                                            full_text  \\\n",
       "18  Kontrastsız Beyin BT  Kafa kaidesi ve kalvaria...   \n",
       "4   KONTRASTSIZ BEYİN BT   İnfratentorial kesitler...   \n",
       "12  Kontrastsız Beyin  BT tetkiki   Kafa kaidesi v...   \n",
       "47  Beyin BT ve orbita BT tetkiklerinde   Posterio...   \n",
       "37  Beyin  BT tetkiki   Kafa kaidesi normal sınırl...   \n",
       "\n",
       "                                        relevant_text  classifications  \\\n",
       "18  Kontrastsız Beyin BT Kafa kaidesi ve kalvarial...                1   \n",
       "4   Sol serebellar hemisferde sekel ??? ensefaloma...                3   \n",
       "12   Periventriküler derin beyaz cevherde kronik i...                3   \n",
       "47  Sağda orbita tavanınd frontal sinüs tabanında ...                0   \n",
       "37  Sağ orbita üst duvarında fraktüre ait görünüm ...                0   \n",
       "\n",
       "    word_count  \n",
       "18          78  \n",
       "4           60  \n",
       "12          57  \n",
       "47          54  \n",
       "37          53  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add word count to the data frame\n",
    "df_final[\"word_count\"] = (\n",
    "    df_final[\"relevant_text\"]\n",
    "    .apply(lambda x: len(str(x).split()))\n",
    ")\n",
    "\n",
    "# word count ascending\n",
    "df_final_sorted = df_final.sort_values([\"word_count\"], ascending=False)\n",
    "df_final_sorted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_sorted.to_csv(transformation.get_project_root() / \"data\" / \"output\" / \"clean_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scaling dynos... done, now running \u001b[32mweb\u001b[39m at 0:Basic\n"
     ]
    }
   ],
   "source": [
    "# stop the instance\n",
    "label_studio.stop_label_studio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_counts = collections.Counter(clean_annotations[\"classifications\"].to_list())\n",
    "\n",
    "# # 1. Emergency\n",
    "# # 2. Normal\n",
    "# # 3. Non Emergency [Doctor]\n",
    "# # 4. Non Emergency [No Doctor]\n",
    "# for item, count in item_counts.items():\n",
    "#     print(f\"Item {item} occurs {count} times in the list.\")\n",
    "\n",
    "# # manual test the word lemmatizer\n",
    "# import simplemma\n",
    "# word = \"hemisferde\"\n",
    "# simplemma.lemmatize(word, lang=\"tr\").lower()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

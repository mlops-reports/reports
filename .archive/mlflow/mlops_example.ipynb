{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0308521",
   "metadata": {},
   "source": [
    " * Reference:\n",
    "https://www.youtube.com/watch?v=Y_hzMnRXjhI&list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S&index=3\n",
    " * ChatGPT: TensorFlow Multiclass Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68974d52-deb7-46b7-b0dc-6d1e70b6d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required packages.\n",
    "\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pathlib\n",
    "\n",
    "import time\n",
    "import csv\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from experiment.api import mlflow as mlflow_api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a58786-2a3f-4c07-85b9-c5747f61a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b1b57-496a-4a0e-8e45-ef3c2162066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "df = pd.read_csv(pathlib.Path(\"../data\") / \"output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07940568-3742-4ec5-ad74-048a3db7e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard random state for all operations\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow = mlflow_api.MLFlow(local_storage=True)\n",
    "mlflow.clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df07d413-c872-4e94-bf5c-8640fa005c03",
   "metadata": {},
   "source": [
    "# 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce4680-013b-499d-98d1-4e4da5834c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check how the data is distributed\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3905641-5a53-4325-be06-be05fbb33f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information about the data columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b260a6d-27ed-4c5a-bd08-60f6b35fd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455aa5fa-39da-4dc8-b8c2-792bccdcccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf759c-3bdb-4e85-8535-81e9e2527efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35668955-a333-49ad-9586-8df181745241",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a26ce86-e82e-4e74-97c9-476445926c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Calculate z-scores of `df`\n",
    "    z_scores = stats.zscore(df)\n",
    "\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "    filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "    df = df[filtered_entries]\n",
    "    return df\n",
    "\n",
    "\n",
    "# Create a reproducible function for the input data\n",
    "def apply_feature_engineering_preprocessing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # Making binary classificaion for the response variable.\n",
    "    # Dividing wine as good and bad by giving the limit for the quality\n",
    "    bins = (2, 6.5, 8)\n",
    "    group_names = [\"bad\", \"good\"]\n",
    "    df[\"quality\"] = pd.cut(df[\"quality\"], bins=bins, labels=group_names)\n",
    "\n",
    "    # Now lets assign a labels to our quality variable\n",
    "    label_quality = LabelEncoder()\n",
    "\n",
    "    # Bad becomes 0 and good becomes 1\n",
    "    df[\"quality\"] = label_quality.fit_transform(df[\"quality\"])\n",
    "\n",
    "    df = remove_outliers(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e94f6-5e04-4cdb-9535-efc68ca56a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply feature engineering\n",
    "df = apply_feature_engineering_preprocessing(df)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba47ffd-7e57-465f-a460-586dda1f634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe4ba2-76cc-49ce-906f-4646805bde87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bbe5a8-9671-4555-b3f1-cfe9dcdba0ee",
   "metadata": {},
   "source": [
    "We have an unbalanced data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbec71f-dad2-49c6-aebf-446afc9331f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now seperate the dataset to feature and target variables\n",
    "X = df.drop(\"quality\", axis=1)\n",
    "y = df[\"quality\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338bb2e-e0e5-44d2-a0ed-971c2de4d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test splitting of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252dd073-e61e-4a12-b945-c1581d6a20ac",
   "metadata": {},
   "source": [
    "# 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c8f68-1efa-48c0-acab-392056dc01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        # Column dropper\n",
    "        (\"column_dropper\", \"drop\", [\"residual sugar\"]),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3342cda1-1754-467e-9b83-25579c553d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pipeline\n",
    "clf = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        (\"scaler\", StandardScaler()),  # scale values before PCA\n",
    "        (\"pca\", PCA()),\n",
    "        (\"classification\", KNeighborsClassifier()),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881faee-3dc0-4f0a-8326-aa3239373854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different hyperparamaters\n",
    "param_grid = [\n",
    "    {\n",
    "        \"pca__n_components\": list(range(3, 10)),\n",
    "        \"classification__n_neighbors\": [3, 4, 5, 6, 7, 8],\n",
    "        \"classification__leaf_size\": [10, 20, 30, 40, 50],\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8328f8-fbf4-42ce-84f1-3bcddca2948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(\n",
    "    clf,\n",
    "    param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    return_train_score=True,\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e631640-2136-4406-a1f3-41c2d111cfa3",
   "metadata": {},
   "source": [
    "### 3.1 Without mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbea5e-1268-45a0-9d4b-7a821d4ab15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e9307-71c0-4d1b-af6c-9739eeff03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing the best parameters for the param_grid:\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb69ed16-c024-4333-b1a6-a8d3d87b9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the best score\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf8085-e7c0-43bc-a1a5-3f04ea50977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the best model in a variable\n",
    "best_model = clf.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bba71e-d13a-466c-9910-dd16066a0b62",
   "metadata": {},
   "source": [
    "### Try on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f402a4-47b7-4a9f-8889-4cd86d17667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use the test set to create predictions\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe99968f-64ed-431a-9d59-ec6dbf386839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the accuracy score manually\n",
    "score = accuracy_score(y_test, predictions)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6784f09-3405-41cd-908b-4a6d6df40b1e",
   "metadata": {},
   "source": [
    "Since the target column is unbalanced, we should check f1 score, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b27d83-0d5a-4cde-9778-710e3d0c66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = f1_score(y_test, predictions)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e085a-e6f4-42d6-872b-b1195bc840d9",
   "metadata": {},
   "source": [
    "As expected, f1 score is much lower because our dataset is unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0d3a2-28d4-4352-87ad-c6af14fd8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693a40a-6fa5-4818-9b31-d7e9eba2a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the confusion matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b44679e-da57-498e-b2ef-bdf29f97f818",
   "metadata": {},
   "source": [
    "### 3.2 With mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498ed9b-0202-49de-8d1a-de32a6161eb8",
   "metadata": {},
   "source": [
    "#### 3.2.1 Train and log models using mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347053a4-ce14-47ff-b802-1665a578e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_different_neighbors(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    y_test: pd.Series,\n",
    "    mlflow: mlflow_api.MLFlow,\n",
    "    leaf_size: int,\n",
    "    n_jobs: int,\n",
    "    neighbor_array: list[int],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    This function tries different neighbors on the model\n",
    "    \"\"\"\n",
    "\n",
    "    max_f1 = 0\n",
    "\n",
    "    for n_neighbors in neighbor_array:\n",
    "        knn = KNeighborsClassifier(\n",
    "            leaf_size=leaf_size, n_neighbors=n_neighbors, n_jobs=n_jobs\n",
    "        )\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        # let's use the test set to create predictions\n",
    "        predictions = knn.predict(X_test)\n",
    "\n",
    "        # calculating the accuracy score manually\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        f1 = f1_score(y_test, predictions)\n",
    "\n",
    "        log_dict = {\n",
    "            \"params\": {\"n_neighbors\": n_neighbors},\n",
    "            \"metrics\": {\"accuracy\": accuracy, \"f1\": f1},\n",
    "        }\n",
    "\n",
    "        temp_run_id = mlflow.log_experiment_run(\n",
    "            model=knn,\n",
    "            experiment_name=\"KNN Experiments\",\n",
    "            run_name=f\"KNN: {n_neighbors}\",\n",
    "            log_dict=log_dict,\n",
    "            registered_model_name=\"knn_n_neighbours\",\n",
    "            tags={\n",
    "                \"model\": \"knn\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if f1 > max_f1:\n",
    "            run_id = temp_run_id\n",
    "\n",
    "    return run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c6c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the tracking server in background\n",
    "mlflow.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c5896-e20f-41c3-91ee-e3a5eb63d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logging with mlflow\n",
    "neighbors = list(range(3, 6))\n",
    "\n",
    "run_id = try_different_neighbors(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    mlflow=mlflow,\n",
    "    leaf_size=10,\n",
    "    n_jobs=-1,\n",
    "    neighbor_array=neighbors,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32df4eb1-41f9-4bef-be5a-8b9d9f565cbd",
   "metadata": {},
   "source": [
    "* n_neighbors = 5 is the best performing model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eafb68-7212-4bde-820d-223104910579",
   "metadata": {},
   "source": [
    "#### 3.1.2 Get predictions directly from an API endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381043dd-2dbe-4583-8ce3-705449b797a5",
   "metadata": {},
   "source": [
    "First, you should run this command to start the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac946a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serve a model with the best f1 score\n",
    "mlflow.serve_model(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497dba31-571c-46dd-9143-a3710d798bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_from_server(row, mlflow: mlflow_api.MLFlow):\n",
    "    \"\"\"\n",
    "    This functions receives response from the machine learning server\n",
    "    \"\"\"\n",
    "\n",
    "    row = row[:-1]\n",
    "    data = {\"dataframe_split\": {\"columns\": list(X_train.columns), \"data\": [row]}}\n",
    "    response = mlflow.get_predictions(data)\n",
    "\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for 5 seconds before the model server starts\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e90f77-e0d4-4f69-9969-c77c7b3b0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad becomes 0 and good becomes 1 \n",
    "with open(\"predictions.csv\", 'wt', encoding='utf-8') as output:\n",
    "   profiles_writer = csv.writer(output, delimiter=',')\n",
    "   columns = list(X_train.columns)\n",
    "\n",
    "   # add column names\n",
    "   columns.append(\"quality\")\n",
    "   columns.append(\"prediction\")\n",
    "   profiles_writer.writerow(columns)\n",
    "   \n",
    "   for row in df.values.tolist():\n",
    "      # add predictions\n",
    "      features = row\n",
    "      features.append(float(get_prediction_from_server(row, mlflow)[\"predictions\"][0]))\n",
    "      profiles_writer.writerow(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee75355514a0472b4f37f8a735b917855400b9863e580426904d1e2f4309b166"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
